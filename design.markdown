# 設計原則

1. （最高原則）無條件保護用戶隱私，設計上避免用戶輸入自己或他人的可識別資訊，因底層 AI 欠缺隱私保護。
2. 由於 AI 的建議不具備法律責任，因此在不違反前述原則下，必須確保用戶知曉 LLM 的限制及風險，避免依賴 AI 做重大決定。重大決定必須轉而尋求專業協助。此「無責任決定」的唯一例外：考量用戶可能限於既無法尋求專業協助，AI 又拒答的情況下，陷入無助的絕望狀態，因此在極端狀況下，AI 可極端謹慎提供建議。
3. 在不違反前述原則下，讓 AI 有效的幫助亞斯/自閉光譜社交。
4. 在不違反前述原則下，盡量符合「neurodivergent-affirming」精神。
5. 在不違反前述原則下，盡量減少用戶實行建議的認知負擔。
6. 在不違反前述原則下，盡量幫助熟悉工具的用戶能快速的探索不同的社交情境。
7. 在不違反前述原則下，盡量減少不熟悉工具的用戶使用工具的認知負擔。
8. 在不違反前述原則下，盡量讓 LLM 容易執行指令（如減少指令長度、減少冗餘、簡化邏輯…）。
9. 在不違反前述原則下，讓指令容易被人類專家維護（此為最低原則）。

# 設計考量

- 以下情況（必須同時成立）可以忍受 UI/UX 改進不立即實現，因為用戶體驗必須以用戶實際回饋為主，而且很容易弄巧成拙。
  1. 只影響用戶體驗（原則 6-7），不太影響核心功能以及安全防護（原則 1-5）
  2. 會大幅增加指令複雜度（損害原則 7-8）
  3. 版本標號中，只是 minor 或 patch 更新，非 major 更新，如 1.0.0 到 1.1.0。

  目前考慮但暫時不做的 UI/UX 改進如下：
  - 快捷指令系統（原則 6），例如 /rest 清楚的代表「休息」

- 判斷用戶的認知負擔、情緒及意圖非常困難，有兩種主要作法：
  1.  嘗試規則化，例如使用關鍵字等等。
  2.  完全放任 LLM 自己判斷。

  第一個作法的問題是常常無法完全規則化，而部分規則化可能反而會增加用戶的認知負擔，不如讓 LLM 自己判斷。讓 LLM 判斷的主要缺點是無法穩定的執行（難以預測結果為何。因此取捨後的規則是：
  1. 對安全性（原則 1-2）有巨大影響的關鍵流程，必須使用規則達到高穩定性。（原則 1-2 比原則 8-9 優先）
  2. 其他不需要穩定的判斷，應由 LLM 自己判斷（原則 8-9）

  例如在以下部分，我們放棄穩定性，讓 LLM 自己判斷；以下是 1. 平衡目標以及 2. 為什麼由 LLM 自己平衡
  - 情緒照顧的「溫和詢問」：最能照顧用戶（原則 3, 原則 7）比穩定性（原則 8）重要；制式化的「溫柔」恐怕效果更差
  - 高社交風險的「中立提醒」：工具的整體必須推廣結構化支持策略（原則 4），但又不能漠視可能風險（原則 3），因此，目前的取捨是使用「中立」語氣，而不是「客觀」（可能過度損害原則 4）或是「支持性」（可能損害原則 3）
  - 搜集細節的「一般情況」跳轉前顯示摘要：幫助用戶了解到底要分析或角色扮演什麼。顯示的好處：如果細節混亂或有許多修正，可以清楚告訴用戶到底在分析或是角色扮演什麼（原則 7）。不顯示的好處：如果用戶清楚的表示是一般情況，而且清楚的寫下情境（通常一般情況不會有太多細節），則該摘要只是馬上重複用戶的話，沒有什麼幫助（原則 6）。由 LLM 自己平衡（甚至不寫平衡什麼）的理由：由於 LLM 必須執行「簡潔整理」，摘要對流程的影響小。目前 LLM 就會根據用戶的輸入風格（輸入細節是否分散、是否為老手風格）自行判斷，只有在整理有助於釐清極度分散的輸入時才執行，其他情況優先跳過。這似乎就是我們要的行為。
  - 角色扮演時社交情境的產生：角色扮演就是要讓 LLM 完全自由發揮，越不可預測越不穩定越好

  而以下的狀況，必須根據原則 1-2 維持極高穩定性：
  - 高壓力安全流程（原則 2）：此安全流程中，必須追求指令穩定性。在確認用戶身心狀態以及意圖時，根據原則 2, 必須謹慎確認用戶真的想要 AI 的答案。只要用戶沒有明確表示，就代表不要。為了強制 LLM 做到這點（防止 LLM 被用戶的元問題或元對話帶跑），可以犧牲原則 8-9，用冗餘重複的指令強迫 LLM 忽略用戶的元對話（如「什麼意思」、「都可以」）。

- 資訊呈現方式：原則 6 要求熟悉工具的用戶（老手）能儘快得到分析結果。最快的結果就是一次互動就拿到詳細分析結果或開始角色扮演。因此：
  1. 從歡迎到拿到詳細分析結果之間，不能有強制性的問題。
  2. 但在這前提之下，必須不嚇跑不熟悉工具的用戶（新手）

  目前的作法採用倒三角形，並在最後的詳細分析之前使用視覺線索（分隔線，「以下是細節」）引導新手跳過

- 避免用戶麻痺：有一些重要的原則，雖然必須確保用戶知道，但又不能淪為重複、制式的提醒，反而讓用戶忽略。因此，重要提醒使用以下策略：
  - 首次顯示後降低頻率：強制顯示一次後，減少出現的次數，讓 LLM 自己判斷「適合」的時機，指令不穩定沒有關係。
  - 客製化：根據上下文，提醒用戶根據原則，最應該考慮的事情，而不直接講原則；由於不容易麻痺，在可以提醒的時機都必須提醒。

  使用「降低頻率」策略的訊息：
  1. 角色扮演開始的「請用虛構資訊，分析有偏見會出錯且隨機」：歡迎流程確保用戶至少會看到一次。
  2. 角色扮演結束時的「鼓勵用戶以真實情境發生的意外事件作啟發，修改或補充虛擬情境」：由於如果是多次互動的角色扮演時，LLM 可能會錯誤的判斷角色扮演已結束，所以必須再減低頻率為「偶爾」。

  使用「客製化」策略的訊息：
  - 角色扮演之中「隱私保護」：根據可能輸入的資料，改變提示。例如可能輸入真名時說「使用化名」。訊息的細節由 LLM 自己判斷。
  - 分析之中的「保持彈性」：根據社交情境，清楚的說明會發生的「意外」，誘導用戶思考並保持彈性。

- 角色扮演的可控參數：角色扮演雖然一部分希望可以模擬用戶的認知負擔，但這不是 LLM 可以偵測或控制的，更不能預設用戶會有什麼樣的認知負擔（原則 4）。因此，可控難度應著重於外部可控的參數，例如「認知壓力」就不是可控的，但「環境噪音」以及「複雜任務」是可控的。

- 結構化支持策略：策略舉例以及分類必須要能滿足以下條件
  1. 違反神經多樣性肯定原則（原則 4）的策略只有在極端狀況才能勉強使用（原則 2 的例外）
  2. 每個詳細的例子都必須有必要性，不能被其他例子包括（重複），也不能太過顯然（無用）；換句話說，必須是去除後 LLM 非常容易漏掉的策略。（原則 8）
  3. 必須避免偏重視覺（原則 4）
  4. 必須能涵蓋 TEACCH 中所有策略（原則 3），但需要經過這兩項調整：
     1. 將適合兒童的策略，在保持原精神下，改寫成適合成人的策略（原則 3）
     2. 任何違反神經多樣性肯定原則（原則 4）的策略都必須改寫、放棄、或加上嚴格條件
